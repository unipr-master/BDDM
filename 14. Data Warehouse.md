## Database operazionali

Il tipo di database trattato finora è di tipo **operazionale**. Questi database sono progettati per supportare le **applicazioni software**, con aggiornamenti in tempo reale (aggiunta, modifica o cancellazione dei dati), e non solo per la consultazione. Per analizzare ed esplorare i dati, è necessario scrivere query complesse, spesso con numerose operazioni di **join** (computazionalmente costose) per unificare i dati in un’unica tabella. Inoltre, è richiesta una **conoscenza tecnica** dello schema del database. Un database operativo **potrebbe non contenere dati storici**, poiché non sono necessari per il funzionamento dell’applicazione.

## Decisioni guidate dai dati

I database operazionali sono più che adeguati per supportare le applicazioni software. Tuttavia, in un contesto aziendale, i dati dovrebbero diventare una **fonte ricca di informazioni**, perché rappresentano la **situazione e il comportamento del business**, e possono **supportare decisioni informate** da parte dei decisori aziendali.

Ma i **decisori** non possono trarre vantaggio direttamente dai dati presenti nei database senza una **conoscenza tecnica approfondita** del modello dei dati.

## Integrazione dei dati

Spesso i decisori vogliono combinare dati provenienti da **diversi database operazionali**, ad esempio dati di vendita con dati pubblicitari. Tuttavia, l’integrazione di database operazionali diversi è estremamente difficile, poiché possono avere **definizioni di dati differenti** e contenuti eterogenei.

## Data Warehouse

Il **data warehouse (DW)** è una **collezione di dati orientata ai soggetti**, **integrata**, **non volatile** e **variabile nel tempo**, progettata per **supportare le decisioni manageriali**.

### Proprietà di un Data Warehouse

- **Orientato ai soggetti**: un data warehouse è progettato per analizzare uno o più soggetti in base alle esigenze analitiche dei manager a diversi livelli del processo decisionale.
- **Integrato**: i contenuti derivano dall'integrazione di dati provenienti da diversi sistemi operazionali e anche da fonti esterne.
- **Non volatile**: un data warehouse **accumula i dati** per lunghi periodi di tempo; le operazioni di modifica o rimozione non sono consentite, tranne l’eliminazione di dati obsoleti non più necessari.
- **Variabile nel tempo**: un data warehouse tiene traccia dell’evoluzione dei dati nel tempo, consentendo ad esempio di osservare l’andamento delle vendite o delle scorte negli ultimi mesi o anni.

## Progettazione dei database

La progettazione dei database tradizionali segue generalmente quattro fasi:

1. **Specifiche dei requisiti**: raccolta delle esigenze degli utenti per definire lo schema del database.
2. **Progettazione concettuale**: descrizione dei dati tramite il modello **entità-relazioni (ER)**.
3. **Progettazione logica**: implementazione secondo il **paradigma relazionale**.
4. **Progettazione fisica**: implementazione concreta sul sistema di gestione del database (DBMS).

Il risultato finale è un database relazionale **altamente normalizzato**, per garantire la **consistenza** sotto aggiornamenti frequenti, ma a costo di **query meno performanti** a causa della presenza di molte tabelle.

## Progettazione di un Data Warehouse

Il paradigma relazionale **non è adatto** ai data warehouse, poiché serve **alta performance per query complesse** di analisi dei dati. È quindi necessario un approccio progettuale orientato a:

- Supportare le **query degli utenti finali** (decisori).
- Favorire la **comprensibilità dei risultati**, senza la necessità di conoscere schemi di dati complessi.
- Privilegiare le **prestazioni**: la **ridondanza è accettata** se porta a vantaggi prestazionali, e il livello di **normalizzazione è ridotto**.

Il paradigma usato è la **modellazione multidimensionale**, anche nota come **dimensional modeling (DM)**.

## Modellazione multidimensionale

La modellazione multidimensionale considera i dati come composti da **fatti collegati a dimensioni**.

- Un **fatto** rappresenta il **focal point dell’analisi**, ovvero l’oggetto principale di interesse (es. nelle analisi di vendita nei negozi, il fatto è la **vendita**).
- Le **misure** quantificano i fatti e sono solitamente valori numerici (es. importo delle vendite, numero di articoli venduti).

Le **dimensioni** permettono di visualizzare le misure da **prospettive diverse**:

- **Dimensione temporale**: per analizzare le vendite in base al periodo.
- **Dimensione geografica**: per analizzare le vendite in base alla distribuzione territoriale dei negozi.

Le dimensioni includono **attributi che formano gerarchie**, permettendo agli utenti decisori di esplorare le misure a **diversi livelli di dettaglio**. Ad esempio:

- **Dimensione temporale**: `ANNO → TRIMESTRE → MESE`
- **Dimensione geografica**: `NAZIONE → REGIONE/PROVINCIA → CITTÀ`

Ogni volta che si attraversa una gerarchia, si verifica un’**aggregazione delle misure**. Ad esempio, passando da mese ad anno, si aggregano i valori delle vendite annuali.

## Schemi a stella e a fiocco di neve

La **modellazione multidimensionale** è un modello concettuale utilizzato per i **data warehouse**. A livello logico, questo modello è solitamente rappresentato tramite tabelle relazionali organizzate secondo **schemi a stella (star schemas)** e **schemi a fiocco di neve (snowflake schemas)**.

Entrambi questi schemi collocano la **tabella dei fatti (fact table)** al centro, collegata a diverse **tabelle delle dimensioni**.

Negli **schemi a stella**, ogni dimensione è rappresentata da **un'unica tabella**, anche in presenza di gerarchie. Ciò comporta una **denormalizzazione**, con **ridondanze** nei dati. Ad esempio, il nome del paese verrà ripetuto per tutte le regioni appartenenti a quel paese.

![[Pasted image 20250429150059.png|400]]

Negli **schemi a fiocco di neve**, al contrario, le dimensioni vengono rappresentate attraverso **più tabelle normalizzate**. Le gerarchie nelle dimensioni sono scomposte in una **struttura a fiocco di neve**, evitando ridondanze. Ad esempio, il paese avrà una propria tabella separata, collegata a quella delle regioni.

![[Pasted image 20250429150120.png|400]]

## Popolamento di un Data Warehouse: processo ETL

**ETL** è l'acronimo di **Extraction, Transformation and Loading**, ovvero **estrazione**, **trasformazione** e **caricamento**. Questo processo è **fondamentale** per il successo di un progetto di data warehousing e si articola in tre fasi principali:

1. **Estrazione** dei dati da vari sistemi sorgente.
2. **Pulizia e trasformazione** dei dati per adattarli al modello del data warehouse.
3. **Caricamento** dei dati trasformati nel data warehouse.

Il processo ETL richiede **notevoli sforzi**: si stima che rappresenti **l’80% del costo complessivo** di un progetto DW.

Durante la **fase di estrazione**, i dati rilevanti vengono prelevati dalle fonti operative. L’**estrazione statica** viene eseguita quando il data warehouse deve essere popolato per la prima volta: consiste essenzialmente nel creare uno **snapshot** (istantanea) dei dati operazionali.

L’**estrazione incrementale**, invece, viene utilizzata per aggiornare il data warehouse e preleva **solo le modifiche** intervenute dall’ultima estrazione. Può basarsi sul **log del DBMS** o sui **timestamp**. La scelta di quali dati estrarre dipende soprattutto dalla **qualità dei dati**.

## ETL: pulizia dei dati

La fase di **data cleaning** ha l’obiettivo di **migliorare la qualità dei dati** provenienti dalle fonti. I problemi da affrontare includono:

- Dati duplicati.    
- Incoerenza tra valori associati.
- Valori mancanti.
- Uso improprio di un campo.
- Valori impossibili o errati.
- Valori incoerenti per la stessa entità a causa di standard differenti.
- Errori di digitazione che generano incoerenze per la stessa entità.

Il processo prevede anche la **conversione dei dati** dal formato operazionale a quello del data warehouse. Questa trasformazione è resa più complessa dall’**eterogeneità delle fonti**, che richiede un passaggio di **integrazione avanzata**.

Ulteriori difficoltà includono:

- Presenza di **testi liberi**, che nascondono informazioni importanti.
- Utilizzo di **formati differenti** per rappresentare gli stessi dati.

## Sistemi OLTP

I sistemi di database tradizionali, noti come OLTP (Online Transaction Processing), sono progettati per supportare le operazioni quotidiane, come la gestione di transazioni e l’accesso concorrente ai dati. Questi sistemi sono pensati per garantire aggiornamenti in tempo reale, mantenendo la coerenza dei dati, e vengono impiegati come basi di supporto per le applicazioni software. Tuttavia, per esplorare e analizzare i dati sono necessarie query complesse, spesso costituite da molteplici operazioni di join, che risultano computazionalmente onerose. Inoltre, la conoscenza tecnica del modello dati è indispensabile per poterne usufruire.

I dati nei database OLTP sono dettagliati, fortemente normalizzati e raramente includono informazioni storiche, poiché non richieste per il funzionamento delle applicazioni operative. Questo rende gli OLTP inadatti all’analisi avanzata, portando alla necessità di un paradigma differente, quello dell’OLAP (Online Analytical Processing). Una query OLTP tipica potrebbe essere "ordini in sospeso per il cliente c1", mentre una query OLAP riguarda aggregazioni più complesse come "totale vendite per prodotto e per cliente".

## Sistemi OLAP

Il paradigma OLAP si concentra sulle query analitiche piuttosto che sulle transazioni. La normalizzazione, utile negli OLTP, è inefficace nell’OLAP, poiché la ricostruzione delle informazioni richiede troppi join. Per questo motivo, le tabelle nei database OLAP sono denormalizzate per aumentare l’efficienza delle interrogazioni. OLAP è progettato per gestire un carico elevato di query, spesso contenenti operazioni di aggregazione. Le tecniche di indicizzazione impiegate nei sistemi OLTP non risultano adeguate, in quanto OLAP accede generalmente a grandi volumi di dati.

La necessità di uno strumento adatto alle analisi complesse ha portato all’introduzione del data warehouse, un sistema progettato specificamente per supportare il paradigma OLAP.

## Data warehouse: sintesi

Il data warehouse è un grande archivio che integra e consolida dati provenienti da fonti eterogenee, sia interne che esterne all'organizzazione. A differenza dei database operazionali, viene aggiornato offline, e non in tempo reale. Utilizza un modello di dati multidimensionale, basato su strutture progettate per facilitare interrogazioni complesse. Le implementazioni tipiche seguono schemi a stella o a fiocco di neve, pensati per ottimizzare l’efficienza delle query OLAP. Nei prossimi approfondimenti, verranno analizzati nel dettaglio l’architettura, la progettazione e le modalità di interrogazione di un data warehouse.

## Architettura: livelli multipli

Nonostante esistano molte varianti architetturali nei sistemi di data warehouse, un elemento comune è la **struttura a più livelli**. Il **livello delle fonti dati** non è propriamente considerato parte integrante del data warehouse, ma rappresenta piuttosto un insieme eterogeneo di dati provenienti da origini differenti, spesso indicato con il termine **data lake**.

![[Pasted image 20250429150329.png]]

Il **livello di back-end** è composto dagli strumenti responsabili dei processi di **estrazione, trasformazione e caricamento (ETL)**, che hanno il compito di alimentare il data warehouse a partire da database operazionali, fonti interne e fonti esterne. In questa fase è coinvolta anche un’area intermedia, chiamata **data staging area**, che funge da spazio temporaneo in cui avviene l’integrazione e la trasformazione dei dati prima del loro caricamento definitivo nel data warehouse.

Il **livello del data warehouse** vero e proprio include un **enterprise data warehouse** e, in alcuni casi, uno o più **data mart**, ovvero sottoinsiemi tematici del magazzino dati principale. Questo livello comprende anche un **repository di metadati**, che contiene informazioni strutturali e semantiche sui dati presenti nel sistema, facilitandone l’interpretazione e l’utilizzo.

Il **livello OLAP** ospita un **server OLAP**, che fornisce una **vista multidimensionale dei dati**, indipendentemente da come essi siano fisicamente memorizzati. Questo server consente agli utenti di navigare e analizzare i dati da prospettive differenti.

Infine, il **livello front-end** è dedicato all’**analisi e alla visualizzazione dei dati**. Qui si trovano gli strumenti utilizzati direttamente dagli utenti finali, come gli strumenti OLAP, gli strumenti di reportistica, quelli statistici e le piattaforme di data mining. Questo livello è l’interfaccia principale attraverso cui i decisori interagiscono con il data warehouse per estrarre conoscenza utile alle decisioni.

## Livello di back-end

Il livello di back-end si occupa dell’intero processo di **estrazione, trasformazione e caricamento (ETL)**, articolato in tre fasi distinte. La **fase di estrazione** consiste nella raccolta dei dati provenienti da fonti multiple ed eterogenee, che possono essere interne o esterne all’organizzazione. Segue la **trasformazione**, che converte i dati dal formato originario delle fonti al formato del data warehouse. Questa fase include diverse operazioni fondamentali: la **pulizia** dei dati, che elimina errori e incoerenze e ne standardizza il formato; l’**integrazione**, che armonizza dati provenienti da sistemi diversi, sia a livello di schema che a livello di contenuti; e infine l’**aggregazione**, che sintetizza le informazioni in base al livello di granularità richiesto dal data warehouse.

La fase finale è il **caricamento**, in cui i dati trasformati vengono immessi nel data warehouse. Questo include anche il **refresh**, ovvero la propagazione periodica degli aggiornamenti dalle fonti originali al magazzino dati, secondo una frequenza prestabilita.

Il back-end include inoltre una **data staging area**, spesso denominata **operational data store**, che rappresenta uno spazio intermedio in cui i dati estratti vengono progressivamente modificati e preparati prima di essere caricati nel sistema principale.

## Livello del Data Warehouse

Il cuore di questo livello è rappresentato da un **enterprise data warehouse**, una base dati centralizzata che abbraccia l’intera organizzazione. Accanto ad esso possono esistere diversi **data mart**, cioè magazzini dati specializzati e focalizzati su specifici reparti o aree funzionali.

Un’altra componente essenziale è il **repository dei metadati**, che conserva informazioni sia a livello **semantico** che **tecnico** sui dati contenuti nel sistema. I metadati aziendali (o business metadata) descrivono il significato dei dati e le regole organizzative, le politiche e i vincoli ad essi associati. I metadati tecnici invece forniscono dettagli su come i dati sono strutturati e memorizzati nei sistemi informatici, oltre alle applicazioni e ai processi che li manipolano.

Il repository dei metadati può contenere una varietà di informazioni. Vi sono descrizioni della struttura del data warehouse e dei data mart sia a livello concettuale e logico (come fatti, dimensioni, gerarchie), sia a livello fisico (come indici e partizioni). Possono essere presenti dati relativi alla sicurezza, comprese le autorizzazioni utente e i controlli di accesso, così come informazioni di monitoraggio come statistiche d’uso, report di errore e log di audit. Inoltre, i metadati possono descrivere le fonti dati, indicandone schemi, proprietà, frequenze di aggiornamento, vincoli legali e modalità di accesso. Infine, sono incluse informazioni relative all’intero processo ETL, come la provenienza dei dati, le regole di estrazione, pulizia e trasformazione applicate nel flusso di alimentazione.

## Livello OLAP

Il livello OLAP è un componente fondamentale nelle implementazioni di data warehouse dedicate alla business intelligence (BI) e alle applicazioni di supporto alle decisioni. Al centro di questo livello si trova il cosiddetto **cubo OLAP**, che consente di eseguire analisi multidimensionali ad alta velocità su grandi volumi di dati, provenienti da un data warehouse, da un data mart o da qualsiasi altro archivio dati centralizzato e unificato. Il cubo OLAP rappresenta un database multidimensionale basato su array, e costituisce il nucleo della maggior parte dei sistemi OLAP. Grazie alla sua struttura, è possibile elaborare e analizzare simultaneamente più dimensioni di dati in modo molto più efficiente rispetto a quanto consentito dai database relazionali tradizionali.

## Livello front-end

Il livello front-end è composto da strumenti client che permettono agli utenti di sfruttare il contenuto del data warehouse in modo efficace. Gli **strumenti OLAP** permettono un’esplorazione interattiva dei dati e la possibilità di formulare query complesse in modo dinamico, offrendo un'interfaccia adatta alla manipolazione diretta delle informazioni.

Gli **strumenti di reportistica** consentono la produzione, distribuzione e gestione di report, che possono essere cartacei, interattivi oppure accessibili tramite il web. I report si basano su query predefinite che richiedono informazioni specifiche in formati strutturati, eseguite con regolarità per soddisfare le necessità informative dell’organizzazione.

Vi sono poi strumenti **statistici**, utilizzati per analizzare e visualizzare i dati del cubo OLAP applicando metodi statistici, spesso con finalità esplorative o di sintesi.

Infine, gli **strumenti di data mining** permettono agli utenti di analizzare i dati per scoprire conoscenze preziose, come schemi ricorrenti e tendenze significative, e offrono anche funzionalità predittive basate sui dati attualmente disponibili.

## Progettazione: modello multidimensionale

Il **modello multidimensionale (MultiDim)** interpreta i dati come appartenenti a uno spazio n-dimensionale, concettualmente rappresentato tramite un **cubo di dati**. Questo cubo è costituito da **dimensioni** e **fatti**. Le dimensioni rappresentano le diverse **prospettive di analisi** dei dati. Per esempio, un cubo tridimensionale relativo alle vendite può essere costruito utilizzando le dimensioni **Prodotto**, **Tempo** e **Cliente**, e avere come **misura** la **Quantità**.

![[Pasted image 20250429151352.png]]

In un esempio concreto, le dimensioni coinvolte sono Cliente, Tempo e Prodotto, mentre i fatti sono rappresentati dalle vendite; ogni piccolo "cubo" interno alla struttura multidimensionale rappresenta una vendita specifica. Le misure associate a ciascun fatto sono valori numerici, come la quantità venduta. Le **attributi** descrivono ulteriormente le dimensioni: per esempio, la dimensione Prodotto può avere attributi come il codice prodotto e il prezzo unitario. Ogni cella del cubo, cioè ogni combinazione possibile di valori delle dimensioni, contiene una misura, come la quantità di unità vendute per categoria di prodotto, trimestre e città del cliente.

## Granularità dei dati

La **granularità dei dati** si riferisce al livello di dettaglio con cui le misure sono rappresentate in relazione a ciascuna dimensione del cubo. Per esempio, le vendite possono essere aggregate alla granularità di **categoria di prodotto**, **trimestre** e **città** del cliente. Le singole istanze di una dimensione sono chiamate **membri**. Ad esempio, "Seafood" e "Beverages" sono membri della dimensione Prodotto alla granularità Categoria.

Un cubo può contenere più misure, come l'importo totale delle vendite (anche se non mostrato nell'esempio), ed è importante notare che nella maggior parte dei casi i cubi risultano **sparsi**, ovvero non tutte le combinazioni di clienti, prodotti e periodi contengono dati, poiché non tutti i clienti acquistano ogni categoria di prodotto in ogni trimestre. Un cubo più raro è invece **denso**, dove la maggior parte delle combinazioni possibili contiene un valore.

## Gerarchie e granularità

Le **gerarchie** consentono di visualizzare i dati a **diversi livelli di granularità**, mappando concetti più dettagliati a concetti più generali. In una gerarchia, il livello inferiore è detto **figlio** (child), mentre quello superiore è detto **genitore** (parent). L’insieme delle relazioni gerarchiche all’interno di una dimensione costituisce lo **schema della dimensione**. Una **istanza di dimensione** include tutti i membri di tutti i livelli.

Nell’esempio presentato, la granularità delle dimensioni è la Categoria per il Prodotto, il Trimestre per il Tempo, e la Città per il Cliente. A seconda delle esigenze, si può desiderare una granularità più fine (ad esempio il Mese) o più aggregata (ad esempio il Paese).

Un esempio tipico di gerarchia nella dimensione Prodotto potrebbe essere: **Prodotto → Categoria → Tutti**, e ciascun livello comprende una serie di membri specifici. Lo stesso vale per le dimensioni Tempo e Cliente.

## Misure e dimensioni

L’**aggregazione delle misure** modifica il livello di astrazione con cui i dati del cubo vengono visualizzati. Le misure possono essere **additive**, **semi-additive** o **non additive**, a seconda delle modalità con cui possono essere aggregate.

Le **misure additive** sono quelle che si possono sommare lungo tutte le dimensioni e rappresentano la tipologia più comune, come le quantità vendute o i ricavi. Le **misure semi-additive** sono quelle che possono essere sommate solo lungo alcune dimensioni. Ad esempio, le quantità in inventario possono essere sommate per prodotto o località, ma non lungo la dimensione del tempo. Le **misure non additive**, invece, non possono essere sommate in alcuna dimensione in modo significativo. Ne sono esempi i prezzi unitari, i costi per unità o i tassi di cambio.

## Altre classificazioni delle misure

Le misure possono anche essere classificate in base alla **funzione di aggregazione** che le definisce. Le **misure distributive** sono quelle per cui l’aggregazione può essere calcolata in modo distribuito, suddividendo i dati in partizioni e aggregandoli separatamente. Esempi di funzioni distributive sono `count`, `sum`, `min`, `max`. Tuttavia, la funzione `count(distinct)` non è distributiva. Per esempio, dato un insieme $S = {3,3,4,5,8,4,7,3,8}$, se lo suddividiamo in sottogruppi ${3,3,4}$, ${5,8,4}$ e ${7,3,8}$, il massimo numero distinto all'interno di ogni gruppo è 3, ma sull'intero insieme è 5.

Le **misure algebriche** possono essere calcolate tramite una funzione algebrica che prende come argomenti i risultati di funzioni distributive. Ad esempio, la media aritmetica può essere ottenuta dividendo la somma dei valori per il numero dei valori, dove entrambe le funzioni sono distributive.

Infine, le **misure o funzioni olistiche** non possono essere calcolate da sottoaggregazioni. Esempi di misure olistiche sono la mediana, il rank e il valore più frequente. Queste misure richiedono la disponibilità dell'intero insieme di dati per poter essere determinate.

## Interrogazione OLAP: operazioni OLAP

Considerando lo stesso esempio già introdotto, esistono diverse **operazioni OLAP** che possono essere applicate per esplorare un cubo di vendite (espresse in migliaia) per categoria di prodotto e città dei clienti. Tra queste operazioni troviamo: **Roll-up**, **Drill-down**, **Sort**, **Pivot**, **Slice** e **Dice**.

## Operazione OLAP: Roll-up 

![[Pasted image 20250429151511.png]]

Nel caso illustrato, si esegue un’operazione di **roll-up** lungo la dimensione Cliente, passando dal livello di dettaglio **Città** al livello più aggregato **Paese (Country)**. In pratica, i dati delle città di Berlino e Colonia vengono aggregati in Germania, mentre quelli di Parigi e Lione vengono aggregati in Francia.

Dopo aver eseguito il roll-up, possiamo osservare le **misure aggregate a livello nazionale**. Dal cubo trasformato si nota, ad esempio, che in **Francia**, le vendite della categoria **Seafood** durante il **primo trimestre (Q1)** sono particolarmente elevate rispetto agli altri dati. Questo risultato evidenzia una tendenza interessante che potrebbe richiedere un’analisi più approfondita.

Per comprendere se questo picco si sia verificato in uno specifico **mese** del primo trimestre, è possibile eseguire l’operazione inversa, ovvero un **drill-down** per tornare a una visualizzazione dettagliata a livello di **Città**, e approfondire ulteriormente lungo la dimensione **Tempo**, passando dal trimestre al **mese**.

## Operazione OLAP: Drill-down

![[Pasted image 20250429153243.png]]

L’operazione di **drill-down** consente di passare da un livello di granularità più grossolano a uno più dettagliato. Nell’esempio mostrato, si scende dal livello **trimestrale (Quarter)** al livello **mensile (Month)** lungo la dimensione **Tempo**.

Nel cubo iniziale, le vendite sono aggregate per ciascun trimestre del 2003. Eseguendo un drill-down, si ottiene una scomposizione più dettagliata dei dati, che ora mostrano le **vendite mensili** per ogni combinazione di città del cliente e categoria di prodotto.

Questa operazione permette di esplorare i dati con maggiore precisione e, nel contesto specifico, consente di verificare se il volume elevato di vendite di prodotti ittici in Francia durante il primo trimestre, osservato nella precedente operazione di roll-up, sia riconducibile a uno o più mesi specifici.

L’aumento del dettaglio rende evidente, ad esempio, che nel mese di gennaio le vendite di seafood in città francesi come Lione e Parigi sono particolarmente alte, suggerendo che l’anomalia nel trimestre sia concentrata proprio in quel periodo.
## Operazione OLAP: Sort

![[Pasted image 20250429153501.png]]

L’operazione di **sort** applicata a una dimensione del cubo consente di **ordinare i membri** di quella dimensione secondo un determinato criterio. Nell’esempio mostrato, l’ordinamento viene eseguito sulla dimensione **Prodotto**, al livello di **Categoria**.

Nel cubo originale, le categorie di prodotto appaiono nell’ordine Beverages, Produce, Condiments e Seafood. Dopo l’operazione di sort, le categorie sono riordinate **alfabeticamente**, ottenendo la sequenza: **Condiments, Seafood, Beverages, Produce**.

Questo tipo di operazione è utile per migliorare la leggibilità e la navigazione all’interno del cubo, specialmente quando si lavora con un numero elevato di membri nelle dimensioni. Ordinare i dati può evidenziare pattern o facilitare il confronto tra valori associati a categorie simili o contigue.

## Operazione OLAP: Pivot

![[Pasted image 20250429153620.png]]

L’operazione di **pivot** consente di **ruotare** le dimensioni del cubo OLAP, modificando l’asse su cui ciascuna dimensione è rappresentata. Questo tipo di trasformazione non altera i dati, ma cambia il punto di vista da cui si osservano.

Nell’esempio, prima del pivot la **dimensione Tempo** (Quarter) si trovava sull’asse verticale (Y), la **dimensione Cliente** (City) sull’asse orizzontale (X), e la **dimensione Prodotto** (Category) sull’asse in profondità (Z).

Dopo aver applicato il pivot, la **dimensione Tempo** è spostata sull’asse orizzontale (X), la **dimensione Cliente** diventa verticale (Y), mentre la **dimensione Prodotto** si trova ora sull’asse di profondità (Z).

Questa operazione è particolarmente utile per **ristrutturare la visualizzazione** del cubo in funzione delle esigenze analitiche dell’utente. Cambiare la prospettiva può facilitare l’individuazione di pattern, relazioni o anomalie tra dimensioni che, nella visualizzazione originale, erano meno evidenti.

## Operazione OLAP: Slice

![[Pasted image 20250429153735.png]]

L’operazione di **slice** consiste nell’**estrarre una singola fetta del cubo** OLAP fissando un valore specifico per una delle dimensioni. In questo caso, viene selezionata una **sezione dei dati relativa alla città di Parigi**.

Il cubo originale contiene dati di vendita per più città, prodotti e trimestri. Con lo slice, si filtra la dimensione **Cliente (City)** scegliendo il valore "Paris", e si visualizza quindi un **sottocubo bidimensionale** che mostra esclusivamente i dati associati a Parigi, suddivisi per **trimestre (Time)** e **categoria di prodotto (Product)**.

Il risultato è una matrice 2D che consente un’analisi mirata delle vendite nella sola città di Parigi, rendendo più semplice il confronto tra trimestri e categorie senza la complessità delle altre dimensioni.
## Operazione OLAP: Dice

![[Pasted image 20250429153831.png]]

L’operazione di **dice** permette di **selezionare un sottocubo tridimensionale** applicando **più condizioni su più dimensioni contemporaneamente**. A differenza dello slice, che fissa un solo valore su una dimensione, il dice consente una selezione più articolata e flessibile.

Nell’esempio mostrato, vengono selezionati solo i dati relativi alle città di **Parigi** e **Lione** nella dimensione **Cliente**, e solo i **primi due trimestri (Q1 e Q2)** nella dimensione **Tempo**. Il risultato è un sottocubo che contiene **solo le combinazioni** corrispondenti a questi criteri, mantenendo intatte le restanti dimensioni, come le **categorie di prodotto**.

Il sottocubo risultante conserva la struttura tridimensionale del cubo originale, ma è limitato alle condizioni specificate. Questo tipo di operazione è particolarmente utile per effettuare analisi mirate su **sottoinsiemi significativi** dei dati, evitando il rumore delle porzioni non rilevanti.

## Esempi di Data Warehouse

Tra le principali soluzioni di data warehousing disponibili oggi troviamo architetture e servizi sia tradizionali che cloud-native. Alcuni esempi significativi includono **Snowflake**, **Google BigQuery**, **Amazon Redshift**, **Azure Synapse Analytics**, **IBM Db2 Warehouse** e **Firebolt**. Queste piattaforme offrono funzionalità avanzate per l’analisi, l’elaborazione e la gestione di grandi volumi di dati, e sono progettate per integrarsi in ecosistemi aziendali complessi, supportando l'accesso rapido e scalabile alle informazioni.

## I flussi di dati stanno diventando inondazioni?

Nel contesto aziendale odierno, sempre più complesso e dinamico, i dati rappresentano una risorsa essenziale. Tuttavia, una delle sfide più grandi che le organizzazioni si trovano ad affrontare è **come organizzare efficacemente i propri dati**, ripensando radicalmente l’infrastruttura informativa.

La transizione verso un modello **as-a-service** per l’archiviazione e la gestione dei dati può alleggerire il peso delle attività tecniche quotidiane e liberare risorse preziose da destinare ad attività strategiche. Per affrontare questo passaggio in modo efficace, è consigliabile:

Anzitutto, valutare attentamente i propri **bisogni attuali** e fare una previsione dei bisogni futuri prima di scegliere un fornitore di servizi. È altrettanto importante comprendere i **piani di sviluppo** dei fornitori potenziali, verificando se saranno in grado di fornire le funzionalità di cui si avrà bisogno. Occorre prestare attenzione al **rischio di lock-in**, ovvero alla dipendenza tecnologica da un singolo vendor. Allo stesso tempo, è fondamentale **promuovere la competenza sui dati all’interno dell’organizzazione**, sia per supportare decisioni informate sia per stimolare l’innovazione. Infine, è necessario valutare e rafforzare la propria **resilienza informatica**, assicurandosi che l'infrastruttura sia protetta contro minacce, errori e attacchi esterni.